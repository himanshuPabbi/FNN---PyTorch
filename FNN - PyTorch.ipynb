{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c62cac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3440c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "\n",
       "[3 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('train_FNN.csv')\n",
    "df_train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fc73f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf027f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200000, 200])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = torch.tensor(df_train.drop(['ID_code', 'target'], axis=1).values.astype(np.float32))\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b922705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.tensor(df_train['target'].values.astype(np.float32))\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95849f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "\n",
    "full_dataset = TensorDataset(features, targets)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d06c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([64, 200]) torch.float32\n",
      "y: torch.Size([64]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"X: {X.shape} {X.dtype}\")\n",
    "    print(f\"y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc64c71",
   "metadata": {},
   "source": [
    "X: torch.Size([64, 200]) torch.float32: Indicates that the input features (X) have a shape of [64, 200], meaning there are 64 samples in the batch, and each sample has 200 features. The data type is torch.float32.\n",
    "\n",
    "y: torch.Size([64]) torch.float32: Indicates that the labels (y) have a shape of [64], meaning there is one label for each sample in the batch. The data type is torch.float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974dfcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNN(\n",
      "  (fc1): Linear(in_features=200, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(200, 16) # Fully connected layer\n",
    "    self.fc2 = nn.Linear(16, 1) # 1 output - binary class\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Activation function for the hidden layer\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    # Activation function for the output layer\n",
    "    x = torch.sigmoid(self.fc2(x))\n",
    "    return x\n",
    "\n",
    "model = FNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e145db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af679e81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.568110  [   64/160000]\n",
      "loss: 0.246174  [ 6464/160000]\n",
      "loss: 0.275184  [12864/160000]\n",
      "loss: 0.196581  [19264/160000]\n",
      "loss: 0.352148  [25664/160000]\n",
      "loss: 0.257878  [32064/160000]\n",
      "loss: 0.280501  [38464/160000]\n",
      "loss: 0.181055  [44864/160000]\n",
      "loss: 0.300710  [51264/160000]\n",
      "loss: 0.280762  [57664/160000]\n",
      "loss: 0.221241  [64064/160000]\n",
      "loss: 0.166118  [70464/160000]\n",
      "loss: 0.374735  [76864/160000]\n",
      "loss: 0.305476  [83264/160000]\n",
      "loss: 0.282701  [89664/160000]\n",
      "loss: 0.394051  [96064/160000]\n",
      "loss: 0.333972  [102464/160000]\n",
      "loss: 0.331721  [108864/160000]\n",
      "loss: 0.304490  [115264/160000]\n",
      "loss: 0.335499  [121664/160000]\n",
      "loss: 0.313643  [128064/160000]\n",
      "loss: 0.302646  [134464/160000]\n",
      "loss: 0.449919  [140864/160000]\n",
      "loss: 0.358036  [147264/160000]\n",
      "loss: 0.155894  [153664/160000]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.299889 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.332807  [   64/160000]\n",
      "loss: 0.198308  [ 6464/160000]\n",
      "loss: 0.269565  [12864/160000]\n",
      "loss: 0.181748  [19264/160000]\n",
      "loss: 0.335007  [25664/160000]\n",
      "loss: 0.250799  [32064/160000]\n",
      "loss: 0.227806  [38464/160000]\n",
      "loss: 0.159886  [44864/160000]\n",
      "loss: 0.288287  [51264/160000]\n",
      "loss: 0.262636  [57664/160000]\n",
      "loss: 0.190588  [64064/160000]\n",
      "loss: 0.129555  [70464/160000]\n",
      "loss: 0.346063  [76864/160000]\n",
      "loss: 0.292531  [83264/160000]\n",
      "loss: 0.257556  [89664/160000]\n",
      "loss: 0.391700  [96064/160000]\n",
      "loss: 0.306154  [102464/160000]\n",
      "loss: 0.318399  [108864/160000]\n",
      "loss: 0.274513  [115264/160000]\n",
      "loss: 0.296531  [121664/160000]\n",
      "loss: 0.310451  [128064/160000]\n",
      "loss: 0.278886  [134464/160000]\n",
      "loss: 0.409783  [140864/160000]\n",
      "loss: 0.327701  [147264/160000]\n",
      "loss: 0.140738  [153664/160000]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.279051 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.307494  [   64/160000]\n",
      "loss: 0.175315  [ 6464/160000]\n",
      "loss: 0.252763  [12864/160000]\n",
      "loss: 0.181609  [19264/160000]\n",
      "loss: 0.315451  [25664/160000]\n",
      "loss: 0.242685  [32064/160000]\n",
      "loss: 0.190615  [38464/160000]\n",
      "loss: 0.145062  [44864/160000]\n",
      "loss: 0.273469  [51264/160000]\n",
      "loss: 0.236282  [57664/160000]\n",
      "loss: 0.172141  [64064/160000]\n",
      "loss: 0.114846  [70464/160000]\n",
      "loss: 0.333907  [76864/160000]\n",
      "loss: 0.285438  [83264/160000]\n",
      "loss: 0.234771  [89664/160000]\n",
      "loss: 0.400404  [96064/160000]\n",
      "loss: 0.267755  [102464/160000]\n",
      "loss: 0.322340  [108864/160000]\n",
      "loss: 0.259835  [115264/160000]\n",
      "loss: 0.277357  [121664/160000]\n",
      "loss: 0.310957  [128064/160000]\n",
      "loss: 0.264864  [134464/160000]\n",
      "loss: 0.379558  [140864/160000]\n",
      "loss: 0.321201  [147264/160000]\n",
      "loss: 0.142911  [153664/160000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.267800 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.288372  [   64/160000]\n",
      "loss: 0.172449  [ 6464/160000]\n",
      "loss: 0.245494  [12864/160000]\n",
      "loss: 0.187339  [19264/160000]\n",
      "loss: 0.296796  [25664/160000]\n",
      "loss: 0.230435  [32064/160000]\n",
      "loss: 0.172727  [38464/160000]\n",
      "loss: 0.140349  [44864/160000]\n",
      "loss: 0.253602  [51264/160000]\n",
      "loss: 0.221933  [57664/160000]\n",
      "loss: 0.161774  [64064/160000]\n",
      "loss: 0.105019  [70464/160000]\n",
      "loss: 0.330298  [76864/160000]\n",
      "loss: 0.270421  [83264/160000]\n",
      "loss: 0.225620  [89664/160000]\n",
      "loss: 0.393596  [96064/160000]\n",
      "loss: 0.241111  [102464/160000]\n",
      "loss: 0.331736  [108864/160000]\n",
      "loss: 0.250305  [115264/160000]\n",
      "loss: 0.271288  [121664/160000]\n",
      "loss: 0.311320  [128064/160000]\n",
      "loss: 0.254764  [134464/160000]\n",
      "loss: 0.359290  [140864/160000]\n",
      "loss: 0.317845  [147264/160000]\n",
      "loss: 0.143228  [153664/160000]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.261924 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.273397  [   64/160000]\n",
      "loss: 0.178154  [ 6464/160000]\n",
      "loss: 0.239513  [12864/160000]\n",
      "loss: 0.193318  [19264/160000]\n",
      "loss: 0.286370  [25664/160000]\n",
      "loss: 0.226886  [32064/160000]\n",
      "loss: 0.165478  [38464/160000]\n",
      "loss: 0.140936  [44864/160000]\n",
      "loss: 0.241098  [51264/160000]\n",
      "loss: 0.213712  [57664/160000]\n",
      "loss: 0.151943  [64064/160000]\n",
      "loss: 0.100361  [70464/160000]\n",
      "loss: 0.326710  [76864/160000]\n",
      "loss: 0.260397  [83264/160000]\n",
      "loss: 0.219352  [89664/160000]\n",
      "loss: 0.385742  [96064/160000]\n",
      "loss: 0.228288  [102464/160000]\n",
      "loss: 0.335337  [108864/160000]\n",
      "loss: 0.245901  [115264/160000]\n",
      "loss: 0.266045  [121664/160000]\n",
      "loss: 0.311887  [128064/160000]\n",
      "loss: 0.248792  [134464/160000]\n",
      "loss: 0.350205  [140864/160000]\n",
      "loss: 0.313858  [147264/160000]\n",
      "loss: 0.143634  [153664/160000]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.258370 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def to_bin(prob, threshold=0.5):\n",
    "  return (prob >= threshold).float()\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  model.train()\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    pred = model(X)\n",
    "    # Squeeze from [64, 1] to [64]\n",
    "    pred = pred.squeeze()\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      loss, current = loss.item(), (batch + 1) * len(X)\n",
    "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  model.eval()\n",
    "  test_loss, correct = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      pred = model(X)\n",
    "      test_loss += loss_fn(pred.squeeze(), y).item()\n",
    "\n",
    "      # Squeeze and convert to bin before comparing with validation targets\n",
    "      pred = to_bin(pred.squeeze())\n",
    "      y = y.squeeze()\n",
    "\n",
    "      correct += (pred == y).type(torch.float).sum().item()\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5517f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
